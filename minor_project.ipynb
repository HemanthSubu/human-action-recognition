{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_4FyGV4psnC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import datetime as dt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "metadata": {
        "id": "hFfnDZuMpzW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/kaggle/input/ucf11-action-recognize/UCF11_updated_mpg'\n",
        "categories = os.listdir(data_dir)\n",
        "num_classes = len(categories)"
      ],
      "metadata": {
        "id": "OBEJ3gDpp2XH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEQUENCE_LENGTH = 8\n",
        "DIM=(64,64)\n",
        "\n",
        "def load_groups(input_folder):\n",
        "    groups = []\n",
        "    label_folders = os.listdir(input_folder)\n",
        "    index = 0\n",
        "    for label_folder in sorted(label_folders):\n",
        "        label_folder_path = os.path.join(input_folder, label_folder)\n",
        "        if os.path.isdir(label_folder_path):\n",
        "            group_folders = os.listdir(label_folder_path)\n",
        "            for group_folder in group_folders:\n",
        "                if group_folder != 'Annotation':\n",
        "                    groups.append([os.path.join(label_folder_path, group_folder), label_folder])\n",
        "            index += 1\n",
        "    return groups\n",
        "def frames_extraction(video_path):\n",
        "    frames_list = []\n",
        "    video_reader = cv2.VideoCapture(video_path)\n",
        "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    skip_frames_window = max(int(video_frames_count / SEQUENCE_LENGTH), 1)\n",
        "\n",
        "    for frame_counter in range(SEQUENCE_LENGTH):\n",
        "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
        "        success, frame = video_reader.read()\n",
        "        if not success:\n",
        "            break\n",
        "        resized_frame = cv2.resize(frame, DIM)\n",
        "        normalized_frame = resized_frame / 255\n",
        "        frames_list.append(normalized_frame)\n",
        "\n",
        "    video_reader.release()\n",
        "    return frames_list\n",
        "\n",
        "def split_into_train_test(groups):\n",
        "    data = []\n",
        "    labels = []\n",
        "    original_labels=[]\n",
        "    label_to_index = {}  # Create a mapping from labels to integer indices\n",
        "    index_to_label = {}  # Create a reverse mapping from integer indices to labels\n",
        "\n",
        "    for group in tqdm(groups):\n",
        "        video_files = os.listdir(group[0])\n",
        "        np.random.shuffle(video_files)\n",
        "        for idx, video_file in enumerate(video_files):\n",
        "            video_file_path = os.path.abspath(os.path.join(group[0], video_file))\n",
        "            frames = frames_extraction(video_file_path)  # Extract frames from video\n",
        "            if len(frames) == SEQUENCE_LENGTH:\n",
        "                data.append(frames)\n",
        "                label = group[1]\n",
        "                original_labels.append(label)\n",
        "                if label not in label_to_index:\n",
        "                    index = len(label_to_index)\n",
        "                    label_to_index[label] = index\n",
        "                    index_to_label[index] = label\n",
        "                labels.append(label_to_index[label])\n",
        "        num_classes = len(label_to_index)\n",
        "        data=np.asarray(data)\n",
        "        label = np.array(label)\n",
        "\n",
        "        encoded_labels = to_categorical(labels, num_classes=num_classes)\n",
        "        train_data, test_data, train_labels, test_labels = train_test_split(data, encoded_labels, test_size=0.2, random_state=19, stratify=encoded_labels)\n",
        "        return train_data, test_data, train_labels, test_labels, original_labels, encoded_labels\n"
      ],
      "metadata": {
        "id": "VQL4V53ep5TS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groups = load_groups(data_dir)"
      ],
      "metadata": {
        "id": "mDY9O4i5rE3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv1D, Activation, SpatialDropout1D, GlobalAveragePooling1D, Dense\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "vBJlqdT6rFfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Inception3D(input_tensor):\n",
        "    # Define the Inception module(Inflated 3D CNN)\n",
        "    conv1x1 = Conv3D(64, (1, 1, 1), padding='same', activation='relu')(input_tensor)\n",
        "    conv3x3_reduce = Conv3D(96, (1, 1, 1), padding='same', activation='relu')(input_tensor)\n",
        "    conv3x3 = Conv3D(128, (3, 3, 3), padding='same', activation='relu')(conv3x3_reduce)\n",
        "    conv5x5_reduce = Conv3D(16, (1, 1, 1), padding='same', activation='relu')(input_tensor)\n",
        "    conv5x5 = Conv3D(32, (5, 5, 5), padding='same', activation='relu')(conv5x5_reduce)\n",
        "    maxpool = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same')(input_tensor)\n",
        "    conv1x1_proj = Conv3D(32, (1, 1, 1), padding='same', activation='relu')(maxpool)\n",
        "    inception_output = tf.keras.layers.concatenate([conv1x1, conv3x3, conv5x5, conv1x1_proj], axis=-1)\n",
        "    return inception_output"
      ],
      "metadata": {
        "id": "L8nzJa-orPOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TemporalConvNet(Layer):\n",
        "    def __init__(self, num_filters, kernel_size, dilations):\n",
        "        super(TemporalConvNet, self).__init__()\n",
        "        self.num_filters = num_filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.dilations = dilations\n",
        "        #self.use_batch_norm = use_batch_norm\n",
        "        self.conv_layers = []\n",
        "\n",
        "        for dilation in dilations:\n",
        "            conv = Conv1D(filters=num_filters,\n",
        "                          kernel_size=kernel_size,\n",
        "                          dilation_rate=dilation,\n",
        "                          padding='causal',\n",
        "                          activation='relu',\n",
        "                          kernel_initializer='he_normal')\n",
        "\n",
        "            self.conv_layers.append(conv)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs\n",
        "        for layer in self.conv_layers:\n",
        "            x = layer(x)\n",
        "            #if self.use_batch_norm:\n",
        "                #x = BatchNormalization()(x)\n",
        "            x = Activation('relu')(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "lKgtLPMYrja2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_filters = 32\n",
        "kernel_size = 3\n",
        "dilations = [1, 2, 4]"
      ],
      "metadata": {
        "id": "07kPCqg9rrpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH, 3)\n",
        "\n",
        "input_tensor = Input(shape=input_shape)\n",
        "\n",
        "I3D_conv1 = Conv3D(64, (7, 7, 7), strides=(2, 2, 2), padding='same', activation='relu')(input_tensor)\n",
        "I3D_maxpool1 = MaxPooling3D((1, 3, 3), strides=(1, 2, 2), padding='same')(I3D_conv1)\n",
        "dropout1 = tf.keras.layers.Dropout(0.4)(I3D_maxpool1)\n",
        "\n",
        "I3D_conv2 = Conv3D(64, (1, 1, 1), padding='same', activation='relu')(dropout1)\n",
        "I3D_conv3 = Conv3D(192, (3, 3, 3), padding='same', activation='relu')(I3D_conv2)\n",
        "I3D_maxpool2 = MaxPooling3D((1, 3, 3), strides=(1, 2, 2), padding='same')(I3D_conv3)\n",
        "dropout2 = tf.keras.layers.Dropout(0.4)(I3D_maxpool2)\n",
        "\n",
        "I3D_inception3a = Inception3D(dropout2)\n",
        "I3D_inception3b = Inception3D(I3D_inception3a)\n",
        "I3D_gap = GlobalAveragePooling3D()(I3D_inception3b)\n",
        "\n",
        "tcn_layer_1 = TemporalConvNet(num_filters, kernel_size, dilations)(input_tensor)\n",
        "tcn_layer_1 = tf.keras.layers.BatchNormalization()(tcn_layer_1)\n",
        "tcn_layer_2 = TemporalConvNet(num_filters, kernel_size, dilations)(tcn_layer_1)\n",
        "tcn_layer_2 = tf.keras.layers.BatchNormalization()(tcn_layer_2)\n",
        "tcn_gap = GlobalAveragePooling3D()(tcn_layer_2)\n",
        "\n",
        "combined_features = tf.keras.layers.concatenate([I3D_gap, tcn_gap])\n",
        "\n",
        "\n",
        "fc1 = Dense(512, activation='relu')(combined_features)\n",
        "output = Dense(NUM_CLASSES, activation='softmax')(fc1)\n",
        "\n",
        "model_com = tf.keras.Model(inputs=input_tensor, outputs=output)\n",
        "\n",
        "model_com.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_com.summary()"
      ],
      "metadata": {
        "id": "ISpcBLeVrwNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data, train_labels, test_labels, original_labels, encoded_labels = split_into_train_test(groups)"
      ],
      "metadata": {
        "id": "usMiFW1Kr2NI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_history = model_com.fit(x =  features_train, y = labels_train, epochs = 90)"
      ],
      "metadata": {
        "id": "jmHxSEAFr9H_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,7))\n",
        "plt.suptitle(\"Model performance\")\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.plot(training_history.history[\"loss\"], label=\"training loss\")\n",
        "plt.plot(training_history.history[\"val_loss\"], label=\"validation loss\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "f3c_ZVXbsM3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(1, 2, 2)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.plot(training_history.history['accuracy'], label=\"training accuracy\")\n",
        "plt.plot(training_history.history['val_accuracy'], label=\"validation accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4BcUfyWesRNX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}